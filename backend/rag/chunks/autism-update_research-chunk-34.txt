good quality. Scores were calculated first by domain and then summed and weighted as described in Table 3 to determine overall study quality. Studies could receive up to two points on the domains of study design, diagnostic approach, participant ascertainment, and intervention, and up to one point on the domains of outcome measurement and statistical analysis. Table 3. Quality scoring algorithm Definition and Scoring Algorithm Rating Score algorithm for internal validity quality rating • ≥8/10 points, including a ++ on study design and ++ on diagnostic approach Good quality • ≥6/10 points, including at least a + on intervention Fair quality • ≤5/10 points Poor quality Data Synthesis We summarized all data qualitatively using evidence tables. We focused on outcomes related to core ASD symptoms (impairments in communication and social interaction and restricted/repetitive behaviors and interests), outcomes including IQ and adaptive behavior, and key symptoms in studies of interventions targeting conditions commonly associated with ASD (e.g., anxiety). For the update, we describe new comparative studies published since the original report, and we make our conclusions and assess the strength of evidence on the cumulative, comparative evidence across the original report and update. Grading the Body of Evidence for Each Key Question The assessment of the literature is done by considering both the observed effectiveness of interventions and the confidence that we have in the stability of those effects in the face of future research. The degree of confidence that the observed effect of an intervention is unlikely to 14 change is presented as strength of evidence, and it can be regarded as insufficient, low, moderate, or high. Strength of evidence describes the adequacy of the current research, both in terms of quantity and quality, as well as the degree to which the entire body of current research provides a consistent and precise estimate of effect. Interventions that have demonstrated benefit in a small number of studies but have not yet been replicated using the most rigorous study designs will therefore have insufficient or low strength of evidence to describe the body of research. Future research may find that the intervention is either effective or ineffective. Strength of the evidence is assessed for a limited set of critical outcomes, typically those related to effectiveness of an intervention. We assessed the strength of the evidence for studies addressing Key Questions 1 and 7, which deal specifically with the outcomes of intervention. Methods for applying strength of evidence assessments are established in the “Methods Guide for Effectiveness and Comparative Effectiveness Reviews” 55 and are based on consideration of five domains (Table 4): study limitations, consistency in direction of the effect, directness in measuring intended outcomes, precision of effect, and reporting bias. Strength of evidence is assessed separately for major intervention-outcome pairs and incorporates data from the entire body of reviewed evidence on behavioral interventions (i.e., comparative studies— both RCTs and prospective and retrospective cohort studies—reported in the 2011 review 39 and studies reported in the current review). We required at least three fair